{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络实现文本情感分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.4.3\n",
      "IPython 5.3.0\n",
      "\n",
      "tensorflow 1.0.1\n",
      "numpy 1.12.0\n",
      "\n",
      "compiler   : GCC 4.8.4\n",
      "system     : Linux\n",
      "release    : 4.9.8-moby\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p tensorflow,numpy -v -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "import time\n",
    "import jieba\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 语料处理\n",
    "\n",
    "* 去除空格/数字/部分标点/少量stopwords\n",
    "* 变长度的句子不便作为神经网络的输入, 因此需先处理为固定长度. 超过固定长度的, 直接截断; 小于固定长度的, 用 padding 补齐.\n",
    "* 将词转换为词序号\n",
    "* 与 nn_sentiment.ipynb 的区别是, 语料由四个文件变成了两个文件."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IGNORE = ' \\n'  # 忽略的字符\n",
    "DOC_LENGTH = 20  # 预设的固定句子长度\n",
    "PADDING = '<PD>'  # 句子长度不足时的占位符\n",
    "\n",
    "def read_docs_and_labels(file):\n",
    "    \"\"\"从文件读取样本, 去除忽略字符, 得到句子和标签列表\"\"\"    \n",
    "    with open(file, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    docs, labels = [], []\n",
    "    for line in lines:\n",
    "        text, label = line.split('\\t')\n",
    "\n",
    "        words_in_doc = []\n",
    "        for word in jieba.cut(text):\n",
    "            if (word not in IGNORE) and (not word.isdigit()):\n",
    "                words_in_doc.append(word)\n",
    "\n",
    "        docs.append(words_in_doc)\n",
    "        labels.append(int(label.strip()))\n",
    "\n",
    "    return docs, labels\n",
    "\n",
    "def fix_doc_length(docs):\n",
    "    \"\"\"将所有样本的词列表调整为固定长度\"\"\"\n",
    "    for i in range(len(docs)):\n",
    "        if len(docs[i]) < DOC_LENGTH:\n",
    "            docs[i].extend([PADDING] * (DOC_LENGTH - len(docs[i])))\n",
    "        else:\n",
    "            docs[i] = docs[i][:DOC_LENGTH]\n",
    "    return docs\n",
    "\n",
    "def get_word_counter(docs):\n",
    "    flat_words = [w for doc in docs for w in doc]\n",
    "    return Counter(flat_words)\n",
    "\n",
    "def build_vocab(word_cnt, limit=3):\n",
    "    \"\"\"建立词表, 仅计入出现次数超过设定值(默认为3)的词\"\"\"\n",
    "    vocab = ['UNK']\n",
    "    for word, count in word_cnt.most_common():\n",
    "        if count > limit:\n",
    "            vocab.append(word)\n",
    "        else:\n",
    "            break\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.742 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** vocab_size = 7024 **\n"
     ]
    }
   ],
   "source": [
    "train_file = 'train_shuffle.txt'\n",
    "test_file = 'test_shuffle.txt'\n",
    "\n",
    "train_docs, train_labels = read_docs_and_labels(train_file)\n",
    "test_docs, test_labels = read_docs_and_labels(test_file)\n",
    "\n",
    "train_docs = fix_doc_length(train_docs)\n",
    "test_docs = fix_doc_length(test_docs)\n",
    "\n",
    "# 由训练样本集建立词表\n",
    "word_cnt = get_word_counter(train_docs)\n",
    "vocab = build_vocab(word_cnt)\n",
    "vocab_size = len(vocab)\n",
    "idx_dict = dict(zip(vocab, range(vocab_size)))  # 由词映射到词序号的字典\n",
    "print('** vocab_size = {} **'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<PD>', 64051), ('，', 36572), ('的', 22834), ('。', 10025), ('了', 8714), (',', 6448), ('是', 6313), ('很', 5024), ('我', 4928), ('酒店', 4025), ('也', 3160), ('在', 2961), ('不错', 2915), ('不', 2885), ('房间', 2863), ('.', 2612), ('！', 2595), ('有', 2562), ('好', 2522), ('都', 2461), ('还', 2449), ('没有', 2326), ('就', 2264), ('、', 1976), ('这', 1922), ('和', 1773), ('比较', 1707), ('：', 1548), ('看', 1532), ('服务', 1515), ('买', 1499), ('感觉', 1477), ('可以', 1468), ('本书', 1309), ('住', 1287), ('非常', 1284), ('就是', 1240), ('到', 1233), ('还是', 1225), ('用', 1198), ('入住', 1188), ('说', 1178), ('月', 1171), ('书', 1066), ('一个', 1046), ('但', 1037), ('系统', 1005), ('这个', 1003), ('日', 959), ('有点', 941)]\n"
     ]
    }
   ],
   "source": [
    "print(word_cnt.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def docs2idxes(docs):\n",
    "    \"\"\"把词列表的列表转换为序号列表的列表\"\"\"\n",
    "    idxes = []\n",
    "    for doc in docs:\n",
    "        idxes_of_one_doc = []\n",
    "        for word in doc:\n",
    "            idx = idx_dict[word] if (word in vocab) else 0\n",
    "            idxes_of_one_doc.append(idx)\n",
    "        idxes.append(idxes_of_one_doc)\n",
    "    return idxes\n",
    "\n",
    "train_idxes = docs2idxes(train_docs)\n",
    "inputs_train = np.asarray(train_idxes)\n",
    "labels_train = np.asarray(train_labels)\n",
    "\n",
    "test_idxes = docs2idxes(test_docs)\n",
    "inputs_test = np.asarray(test_idxes)\n",
    "labels_test = np.asarray(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24586, 20), (24586,), (10538, 20), (10538,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train.shape, labels_train.shape, inputs_test.shape, labels_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义神经网络\n",
    "\n",
    "输入词序号 -> 词向量 -> 卷积层(tanh) -> pool 层 -> 全连接层(sigmoid) -> 输出分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embed_size = 30\n",
    "filter_num = 30\n",
    "window_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'embedding_lookup:0' shape=(?, 20, 30) dtype=float32>,\n",
       " <tf.Tensor 'ExpandDims:0' shape=(?, 20, 30, 1) dtype=float32>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机生成词向量\n",
    "tf.reset_default_graph()\n",
    "W = tf.Variable(tf.random_uniform([vocab_size, word_embed_size], -1.0, 1.0), name=\"W\")\n",
    "\n",
    "inputs = tf.placeholder(tf.int32, shape=[None, DOC_LENGTH], name='inputs')\n",
    "labels = tf.placeholder(tf.int32, shape=[None], name='labels')\n",
    "\n",
    "embeds = tf.nn.embedding_lookup(W, inputs)\n",
    "\n",
    "# 为了适应 conv2d 的参数，拓展了一个维度 (in_channel)，长度是 1\n",
    "embeds_expand = tf.expand_dims(embeds, -1)\n",
    "embeds, embeds_expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'conv-maxpool/conv:0' shape=(?, 18, 1, 30) dtype=float32>,\n",
       " <tf.Tensor 'conv-maxpool/tanh:0' shape=(?, 18, 1, 30) dtype=float32>,\n",
       " <tf.Tensor 'conv-maxpool/pool:0' shape=(?, 1, 1, 30) dtype=float32>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建 conv 层 + pool 层\n",
    "with tf.name_scope(\"conv-maxpool\"):\n",
    "    filter_shape = [window_size, word_embed_size, 1, filter_num]\n",
    "    # W 和 b 是卷积的参数\n",
    "    W = tf.Variable(tf.random_uniform(filter_shape, -1.0, 1.0), name=\"W\")\n",
    "    # bias 和 filter_num 个数是一样的\n",
    "    b = tf.Variable(tf.constant(0.0, shape=[filter_num]), name=\"b\")\n",
    "    # 步长为1，这里不做 Padding，因此句子太短的话可能要丢掉。可自行尝试加 padding\n",
    "    conv = tf.nn.conv2d(\n",
    "        embeds_expand, W, strides=[1, 1, 1, 1],\n",
    "        padding=\"VALID\", name=\"conv\")\n",
    "\n",
    "    # 卷积出来的结果加上 bias\n",
    "    conv_hidden = tf.nn.tanh(tf.add(conv, b), name=\"tanh\")\n",
    "\n",
    "    # 因为没有 padding，出来的结果个数是 sequence_length - window_size + 1\n",
    "    # 如果加了 padding 这里要对应更改\n",
    "    pool = tf.nn.max_pool(\n",
    "        conv_hidden,\n",
    "        ksize=[1, DOC_LENGTH - window_size + 1, 1, 1],\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding='VALID',\n",
    "        name=\"pool\")\n",
    "\n",
    "conv, conv_hidden, pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "童老师提示:\n",
    "> 目前 tensorflow 还不支持动态 max_pool size，所以 ksize 只能用常数固定，\n",
    "> 因为不同句子 sequence_length 不一样，因此目前这里目前还没法做到处理边长句子。  \n",
    "> 一个解决方案是用人工 Padding 的方式，根据语料中最长的句子的长度来扩展所有句子，归一化到统一的长度。即所有句子都通过 Padding 一个特殊符号的方式，扩展为固定长度。\n",
    "> **注意这个是 Tensorflow 目前的限制**，用其他一些支持动态 max_pool 的库不需要 padding。事实上这也会造成计算量的浪费。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None), Dimension(2)]), (24586,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezed_pool = tf.squeeze(pool, [1, 2])\n",
    "raw_output = tf.layers.dense(squeezed_pool, 2)\n",
    "output = tf.nn.softmax(raw_output)\n",
    "raw_output.shape, labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=raw_output, labels=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 训练\n",
    "\n",
    "* 随机梯度下降, 每个训练步读一个样本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(sess, inputs_, labels_, print_matrix=False):\n",
    "    \"\"\"评估模型指标, 并打印输出\"\"\"\n",
    "    pred_prob = sess.run(output, feed_dict={inputs:inputs_, labels:labels_})\n",
    "    preds = np.asarray((pred_prob[:, 1] > 0.5), dtype=int)\n",
    "    mat = sess.run(tf.confusion_matrix(labels_, preds))\n",
    "    tn, fp, fn, tp = mat.reshape(4)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    if print_matrix:\n",
    "        print(' confusion matrix:\\n', mat)\n",
    "    print(' precision {:.3f}, recall {:.3f}'.format(precision, recall))\n",
    "    # return preds, mat, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 000 cost: train 1.79844 / test 1.79639\n",
      " precision nan, recall 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py:7: RuntimeWarning: invalid value encountered in int_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 010 cost: train 0.15011 / test 0.56878\n",
      " precision 0.800, recall 0.866\n",
      "round 020 cost: train 0.02440 / test 0.73127\n",
      " precision 0.892, recall 0.868\n",
      "round 030 cost: train 0.01742 / test 0.82138\n",
      " precision 0.893, recall 0.869\n",
      "round 040 cost: train 0.01290 / test 0.86818\n",
      " precision 0.895, recall 0.877\n",
      "round 050 cost: train 0.01004 / test 0.90180\n",
      " precision 0.896, recall 0.879\n",
      "round 060 cost: train 0.00866 / test 0.93072\n",
      " precision 0.896, recall 0.882\n",
      "round 070 cost: train 0.00754 / test 0.94952\n",
      " precision 0.895, recall 0.883\n",
      "round 080 cost: train 0.00626 / test 0.96319\n",
      " precision 0.894, recall 0.886\n",
      "round 090 cost: train 0.00573 / test 0.98319\n",
      " precision 0.895, recall 0.883\n",
      "Interrupted\n",
      "\n",
      "time: 105.17 s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 2000\n",
    "print_cost_every = 10\n",
    "learning_rate = 1\n",
    "\n",
    "feed_train = {inputs: inputs_train, labels: labels_train}\n",
    "feed_test = {inputs: inputs_test, labels: labels_test}\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "costs_train = []\n",
    "costs_test = []\n",
    "start_time = time.time()\n",
    "\n",
    "num_inputs = len(labels_train)\n",
    "order = np.arange(num_inputs)\n",
    "np.random.shuffle(order)\n",
    "\n",
    "try:\n",
    "    for i in range(epochs):\n",
    "        if i % print_cost_every == 0:\n",
    "            cost_train = sess.run(cost, feed_dict=feed_train)\n",
    "            cost_test = sess.run(cost, feed_dict=feed_test)\n",
    "            costs_train.append(cost_train)\n",
    "            costs_test.append(cost_test)\n",
    "            print('epoch {:03d} cost: train {:.5f} / test {:.5f}'.format(\n",
    "                i, cost_train, cost_test))\n",
    "            evaluate_model(sess, inputs_test, labels_test)\n",
    " \n",
    "        for j in range(0, num_inputs, batch_size):\n",
    "            batch_index = order[j: j + batch_size]\n",
    "            batch_inputs = inputs_train[batch_index]\n",
    "            batch_labels = labels_train[batch_index]\n",
    "            batch_feed = {inputs: batch_inputs, labels: batch_labels}\n",
    "            sess.run(train_step, feed_dict=batch_feed)\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted')\n",
    "finally:\n",
    "    end_time = time.time()\n",
    "    print('\\ntime: {:.2f} s'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMQp+EZEco+AXEckxCn4RkRzz/wNmCTnybYXNmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcbab7be588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(costs_train, label='train cost')\n",
    "plt.plot(costs_test, label='test cost')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** train set **\n",
      " confusion matrix:\n",
      " [[12984    19]\n",
      " [   48 11535]]\n",
      " precision 0.998, recall 0.996\n",
      "\n",
      "** test set **\n",
      " confusion matrix:\n",
      " [[5069  504]\n",
      " [ 587 4378]]\n",
      " precision 0.897, recall 0.882\n"
     ]
    }
   ],
   "source": [
    "print('\\n** train set **')\n",
    "evaluate_model(sess, inputs_train, labels_train, print_matrix=True)\n",
    "print('\\n** test set **')\n",
    "evaluate_model(sess, inputs_test, labels_test, print_matrix=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChangeLog\n",
    "\n",
    "* v-pre\n",
    "    * 条件: 句长 20, 词向量维数 30, filter_num = 15, window size = 3\n",
    "    * 结果:\n",
    "        * train: precision 0.982, recall 0.648\n",
    "        * test: precision 0.920, recall 0.566\n",
    "    * 分析: 训练集都没拟合好, 模型偏 high-bias. 尝试增加参数.\n",
    "* v0\n",
    "    * v-pre -> filter_num 15->30\n",
    "    * 结果\n",
    "        * train: precision 0.825, recall 0.823\n",
    "        * test: precision 0.752, recall 0.780\n",
    "    * 分析: 增加 filter_num 改善了 recall. 但模型仍然偏 high-bias.\n",
    "* v0a\n",
    "    * v0 -> 词向量维数 30->60\n",
    "    * 结果\n",
    "        * train: precision 0.817, recall 0.791\n",
    "        * test: precision 0.761, recall 0.746\n",
    "    * 分析: 没效果. 突然想到: 忽略标点和少数极高频词是否影响了小特征的捕捉?\n",
    "* v1\n",
    "    * v0 -> **不忽略标点和少数极高频词**, 学习率 0.1->0.03\n",
    "    * 结果\n",
    "        * train: precision 0.987, recall 0.984\n",
    "        * test: precision 0.906, recall 0.905\n",
    "* v2\n",
    "    * 改用小批量梯度下降\n",
    "    * 结果\n",
    "        * train: precision 0.996, recall 0.997\n",
    "        * test: precision 0.881, recall 0.881\n",
    "* v2a\n",
    "    * v2 的学习率选得太小了! \n",
    "    * 学习率, 从 0.03 增大到 1, 训练时间从 20+ 分钟减少到 不到2分钟...\n",
    "* 其他改进方向\n",
    "    * 补 padding, 应能提高短句的准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小结\n",
    "\n",
    "常规神经网络的特点就在于, ... 没有特点. 它没有进行特别的优化, 每层神经元与上一层都是完全连接, 导致模型的参数很多, 容易出现过拟合. CNNs 则采用了一种非常巧妙的方法. 在图像处理问题上, CNNs 非常符合直觉, 比如: \n",
    "* 位置不变性 (location invariance): 一个特征无论出现在何处, 都会以同样的方式被捕捉到.\n",
    "* compositionality: 小的特征一级一级向上组成大的特征.\n",
    "\n",
    "在 NLP 领域, 这两种特点并不那么符合直觉. 但实践证明, 它的表现相当好. CNNs 至少有两大优点:\n",
    "* 快\n",
    "* 在模型表现(representation)上很高效 (相比 n-grams)\n",
    "\n",
    "CNNs 模型调校的难点在于, 它有较多超参数需要确定. 比如: \n",
    "* input representations\n",
    "* filter 的数量和尺寸\n",
    "* 是否做 zero padding\n",
    "* 步长(stride size)\n",
    "* pooling 方式 (max 一般优于 average)\n",
    "* 激活函数\n",
    "* 正则化参数\n",
    "* ...\n",
    "\n",
    "[这篇论文](https://arxiv.org/abs/1510.03820) 对不同超参数如何取值进行了研究, 给出了一些实用建议. 需要搭建一个 CNNs 时, 可以从此文推荐的 baseline configuration 开始.\n",
    "\n",
    "### 参考\n",
    "\n",
    "* [udacity Deep Learning - CNNs](https://classroom.udacity.com/courses/ud730/lessons/6377263405/concepts/66010388990923#)\n",
    "    * 直观易懂\n",
    "* [Understanding Convolutional Neural Networks for NLP – WildML](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp)\n",
    "    * 清晰明白, 比较简洁. 文章最后介绍了几篇经典论文.\n",
    "* [CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/convolutional-networks/)\n",
    "    * 内容多而全. 我只看了 Overview 和 Convolutional Layer 这两部分."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "156px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
